# -*- coding: utf-8 -*-
"""pos NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i_H_3J_2LLbtFBb37AWD4w6njtxZEPaD
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import os
import sys
import numpy as np

"""NLP Part-of-Speech Tagging with **spaCy** **bold text**

**Overview**
This project explores the fundamental NLP task of Part-of-Speech tagging—the process of marking up a word in a text as corresponding to a particular part of speech (noun, verb, adjective, etc.), based on both its definition and its context.

#Key Features
**POS Tagging**:
Using the en_core_web_sm English pipeline to identify simple (pos_) and detailed (tag_) grammatical labels.

**Contextual Analysis**:
Demonstrations of how the model handles homonyms (e.g., "left" as a verb vs. "left" as a noun).

**Dependency Visualization:**
Utilizing displacy to generate interactive dependency trees that show the relationship between words.

**Custom Styling:**
Examples of customizing the visual output of dependency graphs (colors, spacing, and compact modes).
"""

pip install spacy

"""**1. Basic POS Extraction**
The notebook demonstrates how to iterate through a processed document to extract grammatical metadata:
"""

import spacy

nlp=spacy.load('en_core_web_sm')

doc=nlp(u"I am learning Natural Language Processing")

doc.text

doc[0]

doc[0].pos_

doc[0].tag_

spacy.explain('NNP')

spacy.explain('PRP')

for word in doc:
    print (word.text,"------->", word.pos_, word.tag_ , spacy.explain(word.tag_))

doc4=nlp(u"The quick brown fox jumped over the lazy dog")

"""**2. Visualizing Dependencies**
The notebook uses spaCy's built-in visualizer to show how words "point" to one another:
"""

from spacy import displacy

displacy.render(doc4,style='dep',jupyter=True)

options={'distance': 80, 'compact': True, 'color': 'white', 'bg': 'green', }

displacy.render(doc4, style='dep', jupyter=True, options=options)

"""**3. Handling Context**
A significant part of the notebook shows the model's intelligence in distinguishing word meanings:


*   "I left the room" → left is identified as a **VERB**.
*   "to the left of the room" → left is identified as a **NOUN**.


"""

doc3=nlp(u"to the left of the room ")
for word in doc3:
    print (word.text,"------->",word.pos_,word.tag_, spacy.explain(word.tag_))

"""**Hidden Markov Models**"""

import spacy

# Recommendation: Use 'md' or 'lg' if 'trf' is too heavy for your machine
nlp = spacy.load('en_core_web_sm')

doc = nlp("will will google campusx")

print(f"{'Word':<10} | {'POS (Simple)':<12} | {'Tag (Detailed)':<10} | {'Meaning'}")
print("-" * 60)

for token in doc:
    print(f"{token.text:<10} | {token.pos_:<12} | {token.tag_:<10} | {spacy.explain(token.tag_)}")